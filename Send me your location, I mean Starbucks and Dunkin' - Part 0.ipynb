{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data prepared!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A brief document of function usage is attached at the bottom*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three kinds of data sets will be needed for this series. However, you can also find the data from the folder and skip this post :)\n",
    "* **Zip code** and **name** of each region in Boston and its neighborhood\n",
    "* **Latitude** and **longitude** of all Starbucks' and Dunkin's store\n",
    "* **Latitude** and **longitude** of all merchants near each store\n",
    "\n",
    "Take a breath. Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as Soup\n",
    "import pandas as pd\n",
    "import json\n",
    "import settings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start from the easiest part! Click [here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=6&cad=rja&uact=8&ved=0ahUKEwjem9KM1rrWAhUHTSYKHcl7C8sQFgjXATAF&url=http%3A%2F%2Fwww.mass.gov%2Feohhs%2Fdocs%2Fdcf%2Fboston-office-by-zipcode.xls&usg=AFQjCNHnNW6W-SOIr1AL6H5w4Q_hKsVW7Q) to download the spreadsheet from Mass.gov.\n",
    "\n",
    "I rename following regions to make them more specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Zip Code|Original Name|New Name|\n",
    "|:---:|:---:|:---:|\n",
    "|02446|Brookline|Brookline North|\n",
    "|02467|Brookline|Brookline Chestnut Hill|\n",
    "|02210|Boston|Boston Seaport|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location of Starbucks and Dunkin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the zip code we get from the above to scrape all geometric data from their official websites. ([Starbucks](https://www.starbucks.com/store-locator) and [Dunkin'](https://www.dunkindonuts.com/en/locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_code = pd.read_table('./data/zip_boston_neighborhood.txt', header=0, names = ['zip_code','region'], dtype = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#To get longitude and latitude from web content\n",
    "def store_dict(source, id, coordinates, zip_code, output):\n",
    "    out = output\n",
    "    for store in source:\n",
    "        if store[id] in output.keys():\n",
    "            continue\n",
    "        else:\n",
    "            out[store[id]] = {'zip_code': zip_code, 'geo': store[coordinates]}\n",
    "    return out  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starbucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb_store = {}\n",
    "for z in zip_code.zip_code.values:\n",
    "    url = \"https://www.starbucks.com/store-locator?place={}\".format(z)\n",
    "    page = requests.get(url)\n",
    "    soup = Soup(page.content, 'html.parser')\n",
    "    store = soup.find_all('div',id = 'bootstrapData')\n",
    "    store = store[0]\n",
    "    store = store.get_text()\n",
    "    sb_dict = json.loads(store)\n",
    "    sb_dict = sb_dict['storeLocator']['locationState']['locations']\n",
    "    sb_store = store_dict(sb_dict, 'id', 'coordinates', z, sb_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dunkin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd_store = {}\n",
    "dd_dict = []\n",
    "for z in zip_code.zip_code.values:\n",
    "    url = \"https://www.mapquestapi.com/search/v2/radius?callback=json111206657990027752725_1504756855257&key=Gmjtd%7Clu6t2luan5%252C72%253Do5-larsq&origin={}&units=m&maxMatches=30&radius=25&hostedData=mqap.33454_DunkinDonuts&ambiguities=ignore&_=1504756855258\".format(z)\n",
    "    page = requests.get(url)\n",
    "    soup = Soup(page.content,'html.parser')\n",
    "    store = soup.get_text()\n",
    "    store = store[store.find(\"(\")+1:store.rfind(\")\")]\n",
    "    dd_dict_temp = json.loads(store)\n",
    "    dd_dict_temp = dd_dict_temp['searchResults']\n",
    "    for dd in dd_dict_temp:\n",
    "        dd_dict.append(dd['fields'])\n",
    "    dd_store = store_dict(dd_dict, 'recordid', 'mqap_geography', z, dd_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sb_nearby = pd.DataFrame([{'id': key, 'lat': sb_store[key]['geo']['latitude'], 'lon': sb_store[key]['geo']['longitude']}, 'zip_code': sb_store[key]['zip_code'] for key in sb_store.keys()])\n",
    "dd_nearby = pd.DataFrame([{'id': key, 'lat': dd_store[key]['geo']['latLng']['lat'],'lon': dd_store[key]['geo']['latLng']['lng']}, 'zip_code': sb_store[key]['zip_code'] for key in dd_store.keys()])\n",
    "sb_nearby['type'] = 'starbucks'\n",
    "dd_nearby['type'] = 'dunkin'\n",
    "sb_nearby['id'] = sb_nearby['id'].astype('str')\n",
    "dd_nearby['id'] = dd_nearby['id'].astype('str')\n",
    "nearby = pd.concat([sb_nearby, dd_nearby],ignore_index=True)\n",
    "nearby = pd.merge(nearby, zip_code, how = 'inner', on = 'zip_code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merchants Nearby "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this is the last data set we need. Before doing it, you need to get a key for [Google Place API](https://developers.google.com/places/web-service/intro). Google Places API Radar Search Service could be used to find up to 200 nearby merchants by **types** for each search. Thus, we are able to get the number of each type of merchants for a given store. A list of valid **types** could be found [here](https://developers.google.com/places/web-service/supported_types). Additional parameters, like **minprice** and **maxprice**, are usefule if you are interested in diving deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#search nearby merchants using Google Place API\n",
    "def search_nearby(datasets, type_list, API_KEY, optional_para = None):\n",
    "    \n",
    "    #the key of the dictionay is used as the suffix for output, the value is used as a part of URL\n",
    "    optional = {'':\"\"}\n",
    "    if optional_para is not None:\n",
    "        for key in optional_para.keys():\n",
    "            optional[key] = \"&{}={}\".format(key,optional_para[key])\n",
    "    \n",
    "    near = {}\n",
    "    for suffix in optional.keys():\n",
    "        for type in type_list:\n",
    "            print(\"Working on {}\".format(type))\n",
    "            new_column = []        \n",
    "            for i in range(len(datasets.values)):\n",
    "                row = datasets.values[i]\n",
    "                url = 'https://maps.googleapis.com/maps/api/place/radarsearch/json?location={},{}&radius=1000&type={}{}&key={}'.format(row[1], row[2], type, optional[suffix], API_KEY)\n",
    "                page = requests.get(url)\n",
    "                soup = Soup(page.content,'html.parser')\n",
    "                place = soup.get_text()\n",
    "                place = json.loads(place)\n",
    "                place = place['results']\n",
    "                for merchant in place:\n",
    "                    near[row[0]] = dict([merchant['place_id']]: merchant['geometry']['location'])\n",
    "                new_column.append(len(place))\n",
    "                print(\"{}% is completed.\".format(round(i/len(datasets.values)*100, 2)))\n",
    "                variable_name = \"{}_{}\".format(type, suffix)\n",
    "                datasets[variable_name] = pd.Series(np.array(new_column), index = datasets.index) \n",
    "    \n",
    "    return (datasets, near)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price level of restaurants and clothing stores is available in Google Place API for search. Thus, I decided to see if Starbucks or Dunkin' has special preference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define cheap and expensive as price level from 0-2 and 3-4 respectively\n",
    "optional_keywords_price_level = {'cheap': {'minprice':0, 'maxprice':2}, 'expensive': {'minprice':3, 'maxprice':4}}\n",
    "#Search nearby cheap and expensive restaurant and clothing store \n",
    "type_list_with_price = ['restaurant','clothing_store']\n",
    "nearby, merchants = search_nearby(nearby, type_list_with_price, settings.API_KEY, optional_keywords_price_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search other types of merchants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Search other nearby merchants\n",
    "type_list = ['atm', 'bakery', 'bank', 'beauty_salon', 'book_store','cafe','car_repair', 'movie_theater', 'convenience_store', 'dentist', 'florist', 'gas_station', 'gym', 'home_goods_store',\\\n",
    "             'hospital', 'laundry', 'liquor_store', 'museum', 'park', 'pharmacy', 'police', 'real_estate_agency', 'school', 'shopping_mall', 'stadium', 'transit_station', 'university',\\\n",
    "             'accounting', 'art_gallery', 'bicycle_store', 'car_dealer', 'car_rental', 'car_repair', 'church', 'city_hall', 'department_store', 'electronics_store', 'embassy', 'funeral_home',\\\n",
    "             'fire_station', 'hindu_temple', 'veterinary_care', 'synagogue', 'post_office', 'physiotherapist', 'parking', 'mosque', 'local_government_office', 'library']\n",
    "nearby, merchants_1 = search_nearby(nearby, type_list, settings.API_KEY)\n",
    "merchants = merchants.update(merchants_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done! Don't forget to save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nearby.to_pickle('nearby.pkl')\n",
    "with open('merchants.pkl', 'wb') as f:\n",
    "    pickle.dump(merchants, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why didn't I use Google API to find all Starbucks' and Dunkin's stores directly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google API does not support searching by zip code. You have to provide a pair of latitude and longitude as the center of region. It might be a little more difficult to search through all regions in Boston. Luckily, we can use zip code in their official searching engine. It makes life much easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have a brief idea of where are those stores located in Boston. Heatmaps will be used to show the density of coffeehouse distribution. Based on the pattern of store locations, it is possible to find some strategies of their business and marketing. And it is also possible to help them find an ideal location according to their location preference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: store_dict\n",
    "\n",
    "**Capability**: \n",
    "Extracting and compiling geometric data of all results\n",
    "\n",
    "**Input**:\n",
    "\n",
    "|variable|Type|Description|\n",
    "|:------|:---|:--------|\n",
    "|source|list|Iterable list. Each element contains information of an individual store|\n",
    "|id|string|The name of field, which contains indentification of a store|\n",
    "|coordinates|string|The name of field, which contains geometric data of a store|\n",
    "|zip_code|string|Zip code used for searching|\n",
    "|output|dict|used for compiling data in each loop|\n",
    "\n",
    "**Output**: A dictionary with keys as store identifications, values as geometric data and zip code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**: search_nearby\n",
    "\n",
    "**Capability**: \n",
    "Collecting the amount of specific type(s) of merchants nearby and their geometry data through Google Place API\n",
    "\n",
    "**Input**:\n",
    "\n",
    "|variable|Type|Description|\n",
    "|:------|:---|:--------|\n",
    "|datasets|dataframe|It contains geometric data of coffeehouse stores. (Columns in order: id, latitude, longitude)|\n",
    "|type_list|list|Iterable list. It contains the type(s) of merchants looking for|\n",
    "|optional_para|dist|(optional) Additional parameter for search|\n",
    "\n",
    "**Output**:    \n",
    "* An updated dataframe with new column(s) of the amount of specific type(s) of merchants \n",
    "* A dictionary with geometry data of all merchants nearby"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
